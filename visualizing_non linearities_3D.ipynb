{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating what happens to regions of data when passed through neural networks and non linearities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook helps to visualize what happens to points as they pass non linearities and a neural network. The analysis is done step by step. The main reason for the development of this notebook is that `02-space_stretching.ipynb` lets you just see what happens after 1 linear transformation and 1 non linear transformation in 2D. This notebook helps you to see what happens after each step of a full neural network with hidden layers in 3D. There is also a part dedicated to 1D transformation at the end of this notebook.\n",
    "\n",
    "You can choose whether your input points should be a 2-D Mesh Grid or a 2-D Gaussian Cloud. You can choose a non linearity: `TanH` or `ReLU`.\n",
    "\n",
    "The code runs the input through two networks\n",
    "\n",
    "1. A 2 Layered Network (Linear Layer, NL, Linear Layer)\n",
    "1. A 3 Layered Network (Linear Layer, NL, Linear Layer, NL, Linear Layer)\n",
    "\n",
    "You can also optionally initialize the weights of the neural network yourself. Initializing weights to different scale of values will enable you to make visualizations similar to `02-space_stretching.ipynb` \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select your choices below\n",
    "\n",
    "Note: Mesh Grid with TanH and  Gaussian Cloud with TanH & Default Manual Weight Initialization give particularly nice visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Type ('Gaussian Cloud' or 'Mesh Grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_type = 'Gaussian Cloud'\n",
    "# input_type = 'Gaussian Cloud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert input_type in ['Mesh Grid', 'Gaussian Cloud']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non Linearity Type ('relu' or 'tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_type = 'tanh'\n",
    "# nl_type = 'tanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert nl_type in ['relu', 'tanh']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Initialization Type ('manual' or 'random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_type = 'manual'\n",
    "# init_type = 'random'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert init_type in ['manual','random']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below there is the code cell to initialize the weights for the first layer of the network. You can modify it to suit your needs and change other layers as well. Refer `Weight Initilization` below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib.pyplot import plot, title, axis\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_default(figsize=(12, 12)):\n",
    "    plt.style.use(['dark_background', 'bmh'])\n",
    "    plt.rc('axes', facecolor='k')\n",
    "    plt.rc('figure', facecolor='k')\n",
    "    plt.rc('figure', figsize=figsize)\n",
    "\n",
    "def show_scatterplot(X, colors, title=''):\n",
    "    colors = colors.cpu().numpy()\n",
    "    X = X.cpu().numpy()\n",
    "    plt.figure()\n",
    "    plt.axis('equal')\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=colors, s=30)\n",
    "    # plt.grid(True)\n",
    "    plt.title(title)\n",
    "    plt.axis()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "set_default()\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-D plotting libraries installation instructions\n",
    "\n",
    "Install ipyml and jupyter extensions by following instructions from https://github.com/matplotlib/jupyter-matplotlib#installatio\n",
    "I have given the commands below for your convenience \\\n",
    "**Note**: These installations have to be done on top of the dl-minicourse conda environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install -c conda-forge ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If using the Notebook\n",
    "# !conda install -c conda-forge widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If using JupyterLab\n",
    "# !conda install nodejs\n",
    "# !jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "# !jupyter labextension install jupyter-matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "def show_scatterplot_3D(X, colors, title=''):\n",
    "    colors = colors.cpu().numpy()\n",
    "    X = X.cpu().numpy()\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_zlabel('z')\n",
    "    #ax.axis('equal')\n",
    "    ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=colors, s=30)\n",
    "    #plt.show()\n",
    "    # plt.grid(True)\n",
    "    plt.title(title)\n",
    "    #ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_type == 'Mesh Grid':\n",
    "    x = np.arange(-5, 5, 0.1)\n",
    "    y = np.arange(-5, 5, 0.1)\n",
    "    xx, yy = np.meshgrid(x, y, sparse=True)\n",
    "    xx = xx.reshape(-1)\n",
    "    yy = yy.reshape(-1)\n",
    "    inputs = torch.from_numpy(np.array([(i,j) for i in xx for j in yy]))\n",
    "elif input_type == 'Gaussian Cloud':    \n",
    "    inputs = torch.randn(1000,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors=inputs[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if nl_type == 'relu':\n",
    "    NL = nn.ReLU()\n",
    "elif nl_type == 'tanh':\n",
    "    NL = nn.Tanh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are 6 network models defined below. \n",
    "1. Only the first linear layer (2D -> 3D)\n",
    "2. The first linear (2D -> 3D) and non linear layer\n",
    "3. Linear (2D -> 3D), NL and Linear layer (3D -> 2D)\n",
    "4. Linear (2D -> 3D), NL and Hidden layer (3D -> 3D)\n",
    "5. Linear (2D -> 3D), NL, Hidden (3D -> 3D), NL layer\n",
    "6. Linear (2D -> 3D), NL, Hidden (3D -> 3D), NL and Linear layer (3D -> 2D)\n",
    "\n",
    "All the 6 networks are made to have the same weight for the first layer in the cell below. You can manually change this weight if you want.\n",
    "The 3 networks with hidden layers are made to have the same weight for the hidden layer. You can manually change this too.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=3, bias=False)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=3, out_features=3, bias=False)\n",
       "  (3): Tanh()\n",
       "  (4): Linear(in_features=3, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_data = 2\n",
    "n_hidden = 3\n",
    "bias = False\n",
    "\n",
    "\n",
    "linear_model = nn.Sequential(\n",
    "        nn.Linear(n_data, n_hidden, bias=bias)\n",
    ")\n",
    "\n",
    "linear_model.to(device)\n",
    "\n",
    "non_linear_model = nn.Sequential(\n",
    "        nn.Linear(n_data, n_hidden, bias=bias),\n",
    "        NL\n",
    ")\n",
    "\n",
    "non_linear_model.to(device)\n",
    "\n",
    "\n",
    "full_model = nn.Sequential(\n",
    "        nn.Linear(n_data, n_hidden, bias=bias),\n",
    "        NL,\n",
    "        nn.Linear(n_hidden,n_data, bias=bias),\n",
    ")\n",
    "\n",
    "full_model.to(device)\n",
    "\n",
    "\n",
    "model_extra_hidden_layer = nn.Sequential(\n",
    "        nn.Linear(n_data, n_hidden, bias=bias),\n",
    "        NL,\n",
    "        nn.Linear(n_hidden,n_hidden, bias=bias)\n",
    ")\n",
    "\n",
    "model_extra_hidden_layer.to(device)\n",
    "\n",
    "model_extra_hidden_layer_nl = nn.Sequential(\n",
    "        nn.Linear(n_data, n_hidden, bias=bias),\n",
    "        NL,\n",
    "        nn.Linear(n_hidden,n_hidden, bias=bias),\n",
    "        NL\n",
    ")\n",
    "\n",
    "model_extra_hidden_layer_nl.to(device)\n",
    "\n",
    "\n",
    "full_model_extra_hidden_layer = nn.Sequential(\n",
    "        nn.Linear(n_data, n_hidden, bias=bias),\n",
    "        NL,\n",
    "        nn.Linear(n_hidden,n_hidden, bias=bias),\n",
    "        NL,\n",
    "        nn.Linear(n_hidden,n_data, bias=bias),\n",
    ")\n",
    "\n",
    "full_model_extra_hidden_layer.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = 3\n",
    "if n_hidden == 2:\n",
    "    first_layer_initial_weights = S*torch.eye(2)  \n",
    "else:\n",
    "    if n_hidden == 4:\n",
    "        additional_weight_matrix = torch.ones(2,2)\n",
    "    elif n_hidden == 3:\n",
    "        additional_weight_matrix = torch.ones(1,2)\n",
    "    first_layer_initial_weights = S*torch.cat((torch.eye(2),2*additional_weight_matrix),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of the first linear layer\n",
      "tensor([[3., 0.],\n",
      "        [0., 3.],\n",
      "        [6., 6.]])\n",
      "Weights of the last linear layer\n",
      "tensor([[ 0.1345, -0.5229,  0.5245],\n",
      "        [ 0.2360,  0.4346, -0.5221]])\n",
      "Weights of the hidden linear layer\n",
      "tensor([[ 0.3411,  0.0557,  0.3757],\n",
      "        [-0.2658, -0.1838, -0.3370],\n",
      "        [-0.4643,  0.2287, -0.4700]])\n"
     ]
    }
   ],
   "source": [
    "if init_type =='manual':\n",
    "    W1 = first_layer_initial_weights\n",
    "elif init_type == 'random':\n",
    "    W1 = linear_model[0].weight.data\n",
    "non_linear_model[0].weight.data.copy_(W1)\n",
    "full_model[0].weight.data.copy_(W1)\n",
    "model_extra_hidden_layer[0].weight.data.copy_(W1)\n",
    "model_extra_hidden_layer_nl[0].weight.data.copy_(W1)\n",
    "full_model_extra_hidden_layer[0].weight.data.copy_(W1)\n",
    "\n",
    "W3 = full_model[2].weight.data\n",
    "\n",
    "full_model_extra_hidden_layer[4].weight.data.copy_(W3)\n",
    "\n",
    "W2 = model_extra_hidden_layer[2].weight.data\n",
    "model_extra_hidden_layer_nl[2].weight.data.copy_(W2)\n",
    "full_model_extra_hidden_layer[2].weight.data.copy_(W2)\n",
    "\n",
    "print('Weights of the first linear layer')\n",
    "print(W1)\n",
    "print('Weights of the last linear layer')\n",
    "print(W3)\n",
    "print('Weights of the hidden linear layer')\n",
    "print(W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = inputs.double()\n",
    "linear_model=linear_model.double()\n",
    "non_linear_model=non_linear_model.double()\n",
    "full_model=full_model.double()\n",
    "model_extra_hidden_layer = model_extra_hidden_layer.double()\n",
    "model_extra_hidden_layer_nl = model_extra_hidden_layer_nl.double()\n",
    "full_model_extra_hidden_layer = full_model_extra_hidden_layer.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_1 = linear_model(inputs)\n",
    "outputs_2 = non_linear_model(inputs)\n",
    "outputs_3 = full_model(inputs)\n",
    "outputs_4 = model_extra_hidden_layer(inputs)\n",
    "outputs_5 = model_extra_hidden_layer_nl(inputs)\n",
    "outputs_6 = full_model_extra_hidden_layer(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following is the step by step visualization of what happens to the input after each layer. \n",
    "Notice that the color scheme remains constant throughout so it is easier to visualize what happens to regions of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac174034ae134af09b2779ff834db0a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of first linear layer\n",
      "tensor([[3., 0.],\n",
      "        [0., 3.],\n",
      "        [6., 6.]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f51f7530931a4a468df2121795a76d58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of first linear layer\n",
      "tensor([[3., 0.],\n",
      "        [0., 3.],\n",
      "        [6., 6.]])\n",
      "Non Linearity:\n",
      "Tanh()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "394d64d276a14cd4864f7f141475cb53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of first linear layer\n",
      "tensor([[3., 0.],\n",
      "        [0., 3.],\n",
      "        [6., 6.]])\n",
      "Non Linearity:\n",
      "Tanh()\n",
      "Weights of last linear layer\n",
      "tensor([[ 0.1345, -0.5229,  0.5245],\n",
      "        [ 0.2360,  0.4346, -0.5221]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d56a40f2c2f4aab958600d783464918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of first linear layer\n",
      "tensor([[3., 0.],\n",
      "        [0., 3.],\n",
      "        [6., 6.]])\n",
      "Non Linearity:\n",
      "Tanh()\n",
      "Weights of hidden linear layer\n",
      "tensor([[ 0.3411,  0.0557,  0.3757],\n",
      "        [-0.2658, -0.1838, -0.3370],\n",
      "        [-0.4643,  0.2287, -0.4700]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32646337dcf4b1cb031c0e7918cfe86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of first linear layer\n",
      "tensor([[3., 0.],\n",
      "        [0., 3.],\n",
      "        [6., 6.]])\n",
      "Non Linearity:\n",
      "Tanh()\n",
      "Weights of hidden linear layer\n",
      "tensor([[ 0.3411,  0.0557,  0.3757],\n",
      "        [-0.2658, -0.1838, -0.3370],\n",
      "        [-0.4643,  0.2287, -0.4700]])\n",
      "Non Linearity:\n",
      "Tanh()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e191bd5291e41af8936f48602370090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of first linear layer\n",
      "tensor([[3., 0.],\n",
      "        [0., 3.],\n",
      "        [6., 6.]])\n",
      "Non Linearity:\n",
      "Tanh()\n",
      "Weights of hidden linear layer\n",
      "tensor([[ 0.3411,  0.0557,  0.3757],\n",
      "        [-0.2658, -0.1838, -0.3370],\n",
      "        [-0.4643,  0.2287, -0.4700]])\n",
      "Non Linearity:\n",
      "Tanh()\n",
      "Weights of last linear layer\n",
      "tensor([[ 0.1345, -0.5229,  0.5245],\n",
      "        [ 0.2360,  0.4346, -0.5221]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b5748566194efe9005edfb31f72700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Input Data')\n",
    "show_scatterplot(inputs.data,colors = colors, title='Input')\n",
    "\n",
    "print('Weights of first linear layer')\n",
    "print(W1)\n",
    "show_scatterplot_3D(outputs_1.data,colors = colors, title='After Linear Layer (2D -> 3D)')\n",
    "\n",
    "\n",
    "print('Weights of first linear layer')\n",
    "print(W1)\n",
    "print('Non Linearity:')\n",
    "print(NL)\n",
    "show_scatterplot_3D(outputs_2.data,colors = colors, title='After Linear Layer (2D -> 3D) + NL')\n",
    "\n",
    "\n",
    "print('Weights of first linear layer')\n",
    "print(W1)\n",
    "print('Non Linearity:')\n",
    "print(NL)\n",
    "print('Weights of last linear layer')\n",
    "print(W3)\n",
    "show_scatterplot(outputs_3.data,colors = colors, title='After Linear Layer (2D -> 3D) + NL + Linear Layer (3D -> 2D)')\n",
    "\n",
    "\n",
    "print('Weights of first linear layer')\n",
    "print(W1)\n",
    "print('Non Linearity:')\n",
    "print(NL)\n",
    "print('Weights of hidden linear layer')\n",
    "print(W2)\n",
    "show_scatterplot_3D(outputs_4.data,colors = colors, title='After Linear Layer (2D -> 3D) + NL + Hidden Layer (3D -> 3D)')\n",
    "\n",
    "\n",
    "print('Weights of first linear layer')\n",
    "print(W1)\n",
    "print('Non Linearity:')\n",
    "print(NL)\n",
    "print('Weights of hidden linear layer')\n",
    "print(W2)\n",
    "print('Non Linearity:')\n",
    "print(NL)\n",
    "show_scatterplot_3D(outputs_5.data,colors = colors, title='After Linear Layer (2D -> 3D) + NL + Hidden Layer (3D -> 3D) + NL')\n",
    "\n",
    "\n",
    "print('Weights of first linear layer')\n",
    "print(W1)\n",
    "print('Non Linearity:')\n",
    "print(NL)\n",
    "print('Weights of hidden linear layer')\n",
    "print(W2)\n",
    "print('Non Linearity:')\n",
    "print(NL)\n",
    "print('Weights of last linear layer')\n",
    "print(W3)\n",
    "show_scatterplot(outputs_6.data,colors = colors, title='After Linear Layer (2D -> 3D) + NL + Hidden Layer (3D -> 3D) + NL + Linear Layer (3D -> 2D)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=50\n",
    "if input_type == 'Mesh Grid':\n",
    "    inputs = torch.linspace(-1,1,n)\n",
    "elif input_type == 'Gaussian Cloud':    \n",
    "    inputs = torch.randn(n,1)\n",
    "inputs_in_2d = torch.from_numpy(np.array(list(map(lambda x: (np.array([x,0])),inputs)))) # Converting 1-D inputs form (x) -> (x,0) for visualizing as a scatter plot\n",
    "inputs = inputs.view(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are 3 network models defined below. \n",
    "1. Only the first linear layer\n",
    "2. The first linear and non linear layer\n",
    "3. Linear, NL and Linear layer\n",
    "\n",
    "All the 3 networks are made to have the same weight for the first layer in the cell below. You can manually change this weight if you want.\n",
    "\n",
    "The full network converts the 1-D data into 2-D, passes it through a NL and converts it back to 1-D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1, out_features=2, bias=False)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=2, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_data = 1\n",
    "n_hidden = 2\n",
    "bias = False\n",
    "if nl_type == 'relu':\n",
    "    NL = nn.ReLU()\n",
    "elif nl_type == 'tanh':\n",
    "    NL = nn.Tanh()\n",
    "\n",
    "linear_model = nn.Sequential(\n",
    "        nn.Linear(n_data, n_hidden, bias=bias)\n",
    ")\n",
    "\n",
    "linear_model.to(device)\n",
    "\n",
    "non_linear_model = nn.Sequential(\n",
    "        nn.Linear(n_data, n_hidden, bias=bias),\n",
    "        NL\n",
    ")\n",
    "\n",
    "non_linear_model.to(device)\n",
    "\n",
    "full_model = nn.Sequential(\n",
    "        nn.Linear(n_data, n_hidden, bias=bias),\n",
    "        NL,\n",
    "        nn.Linear(n_hidden,n_data, bias=bias)\n",
    ")\n",
    "\n",
    "full_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of the first linear layer\n",
      "tensor([[-0.8563],\n",
      "        [ 0.9086]])\n",
      "Weights of the last linear layer\n",
      "tensor([[ 0.1840, -0.2933]])\n"
     ]
    }
   ],
   "source": [
    "W = linear_model[0].weight.data\n",
    "print('Weights of the first linear layer')\n",
    "print(W)\n",
    "non_linear_model[0].weight.data.copy_(W)\n",
    "full_model[0].weight.data.copy_(W)\n",
    "print('Weights of the last linear layer')\n",
    "print(full_model[2].weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_1 = linear_model(inputs)\n",
    "outputs_2 = non_linear_model(inputs)\n",
    "outputs_3 = full_model(inputs)\n",
    "outputs_3_in_2d = torch.from_numpy(np.array(list(map(lambda x: (np.array([x,0])),outputs_3.data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors=torch.cat((torch.zeros(25),torch.ones(25)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following is the step by step visualization of what happens to the input after each layer. \n",
    "Notice that the color scheme remains constant throughout so it is easier to visualize what happens to regions of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of the first linear layer\n",
      "tensor([[-0.8563],\n",
      "        [ 0.9086]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of the first linear layer\n",
      "tensor([[-0.8563],\n",
      "        [ 0.9086]])\n",
      "Non Linearity\n",
      "ReLU()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of the first linear layer\n",
      "tensor([[-0.8563],\n",
      "        [ 0.9086]])\n",
      "Non Linearity\n",
      "ReLU()\n",
      "Weights of the last linear layer\n",
      "tensor([[ 0.1840, -0.2933]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Input Data')\n",
    "show_scatterplot(inputs_in_2d.data,colors=colors)\n",
    "\n",
    "print('Weights of the first linear layer')\n",
    "print(W)\n",
    "show_scatterplot(outputs_1.data,colors=colors)\n",
    "\n",
    "print('Weights of the first linear layer')\n",
    "print(W)\n",
    "print('Non Linearity')\n",
    "print(NL)\n",
    "show_scatterplot(outputs_2.data,colors=colors)\n",
    "\n",
    "\n",
    "print('Weights of the first linear layer')\n",
    "print(W)\n",
    "print('Non Linearity')\n",
    "print(NL)\n",
    "print('Weights of the last linear layer')\n",
    "print(full_model[2].weight.data)\n",
    "show_scatterplot(outputs_3_in_2d,colors=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from celluloid import Camera\n",
    "# import time\n",
    "# anim_data_np = [inputs_in_2d.data.numpy(),outputs_1.data.numpy(),outputs_2.data.numpy(),outputs_3_in_2d.data.numpy()]\n",
    "# anim_data = [inputs_in_2d.data,outputs_1.data,outputs_2.data,outputs_3_in_2d.data]\n",
    "# fig = plt.figure()\n",
    "# camera = Camera(fig)\n",
    "# for i in range(len(anim_data)):\n",
    "#     plt.scatter(anim_data[i][:, 0], anim_data[i][:, 1], c=colors.numpy(), s=30)\n",
    "#     #plt.plot(anim_data[i][:,0],anim_data[i][:,1])\n",
    "#     camera.snap()\n",
    "#     time.sleep(20)\n",
    "    \n",
    "# animation = camera.animate()\n",
    "# animation.save('celluloid_minimal.gif', writer = 'imagemagick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl-minicourse] *",
   "language": "python",
   "name": "conda-env-dl-minicourse-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
